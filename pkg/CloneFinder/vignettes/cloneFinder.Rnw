%\VignetteIndexEntry{CloneFinder}
%\VignetteKeywords{SNP,Copy Number,clone,subclone}
%\VignetteDepends{stats}
%\VignettePackage{CloneFinder}
\documentclass{article}

\usepackage{hyperref}

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textit{#1}}}

\title{Inferring Clonal Structure From SNP Copy Number Data}
\author{Kevin R. Coombes and Mark Zucker}

\begin{document}

\maketitle
\tableofcontents

\section{Introduction}


\section{Getting Started}

We start by loading the package into the current R session.
<<lib>>=
library(CloneFinder)
@ 

\section{Structure of the Algorithm}

\subsection{Compartments}
We introduce the term \textit{compartment} to describe a pure
(undiluted, homogeneous) copy number state.  For modeling purposes, we
assume that there is a fixed number of pure compartments.  In
particular, we do not model high amplifications in copy number, mainly
because they are simply indistinguishable in SNP copy number data.

We consider the following comparments:
\begin{itemize}
\item Most segments of the genome appear in two different (i.e.,
  heterozygous) copies.  In this state, we expect the true log R ratio
  ($LRR$) to equal zero and the true B allele frequency ($BAF$) to
  equal one-half.
\item Some segments contain two identical (homozygous) copies of the
  genomic material, either through inheritance (identical by descent)
  or because of a somatic loss of heterozygosity (LOH).  In this case,
  the true $LRR = 0$ and the true $BAF = 0$.
\item Another compartment arises when all cells in the sample being
  measured have lost one copy of a genomic segment.  In this case,
  the true $LRR = \log(1/2)$ and the true $BAF = 0$.
\item Similarly, it is possible for all cells in the sample to acquire a
  gain of the same genomic segment.  In this case, the true
  $LRR=\log(3/2)$ and the true $BAF = 1/3$.
\item A gain of two copies of the same piece of a chromosome has true
  $LRR=\log(2)$ and true $BAF = 1/4$.   (For modeling purpoises, we
  ignore the tetraploidy case when both parental chromosomes are
  duplicated, leading to $LRR=\log(2)$ and $BAF = 1/2$.)  We also
  ignore higher copy number gains. 
\item The case when both copies of a genomic segment is problematic,
  since the true $LRR = \log(0) = -\infty$ and the true $BAF = 0/0$ is
  undefined.
\end{itemize}

\paragraph{Code Example}
A compartment is modeled in the \texttt{CloneFinder} package by the
\texttt{CompartmentModel} class, which is implemented as:
<<commod>>=
showClass("CompartmentModel")
@ 

In this preliminary implementation, instead of using actual
$(LRR,BAF)$ pairs, we instead simulate and model the data as though it
comes from a pair of independent normal distributions.  For example,
<<compartments>>=
set.seed(2726642) # for reproducible examples
nSeg <-  1000     # number of segments supposedly found by CBS
markers <- round(runif(nSeg, 25, 1000))  # numbers of markers
# set 'known' centers for the pure compartments
xy <- data.frame(x = c(0.2, 0.7, 0.8, 0.1, 0.4),
                 y = c(0.2, 0.3, 0.5, 0.9, 0.7))
# build the model. sigma0 = std dev at one marker
baseModel <- CompartmentModel(markers, xy, sigma0=0.25)
rm(nSeg, xy)
@ 

Before we can show you how the modeling works, we have to simulate
data from a tumor.
<<tumor>>=
wts <- rev(5^(1:5))
wts <- wts/sum(wts)  # prevalence of differnt compartments
fracs <- c(5, 3, 1)  # relative frequency of subclones
# length of 'fracs' is the number of clones
# now simulate a tumor;
tumor <- Tumor(baseModel, fracs, wts)
rm(wts, fracs, markers, baseModel)
class(tumor)
@ 
Objects of the \texttt{Tumor} class are basically multivariate
distributions; you have to make another function call to
sample/simulate data from them.
<<simdata>>=
simdata <- generateData(tumor)
@ 
\begin{figure}
<<fig=TRUE,echo=FALSE>>=
sizeplot(simdata, tumor)
@ 
\caption{Sized scatter plot of simulated data.}
\label{sizeplot}
\end{figure}

\subsection{Segment-Level Modeling}
After the SNP copy number data has been segmented (typically by
applying something like the circular binary segmentaion algorithm
implemented in the \texttt{DNAcopy} R package), we model the data as
arising from a mixture (in terms of cells in the biological sample) of
the pure compartments.  We use the following notation:
\begin{itemize}
\item Let $K$ denote the number of pure compartments.
\item For $k \in 1,\ldots,K$, let $C_k$ be the statistical
  distribution modeling the data observed from a single SNP marker
  in a region consisting of cells from the $k^{\rm th}$ compartment.
\item Let $S$ be the number of segments.
\item For $s \in 1,\ldots,S$, let $M_s$ be the number of SNP markers
  contained in the $s^{\rm th}$ segment.
\item Becuase the data in the $s^{\rm th}$ segment is obtained by
  averaging over $M_s$ markers, the observed data even for a pure
  compartment should arise from a modified distribution 
  $C_{s,k} = C_k\{M_s\}$, which typically involves dividing the
  standard deviation by $\sqrt{M_s}$. 
\end{itemize}

Now the observed pair of measurements $X = (LRR, BAF)$ on each segment
$s$ is modeled by an equation of the form
$$ X_s \sim \sum_{k=1}^K \varphi_{s,k} C_k\{M_s\}, $$
with the obvious constraints that every parameter satisfies $ 0 \le
\varphi_{s,k} \le 1$ and
$$\forall s, \sum_{k=1}^K \varphi_{s,k} = 1. $$

\subsubsection{Preliminary Estimate of Compartment Frequencies ($\varphi$)}
In spite of having only one observed data point per segment, we can
still get an estimate of the vector $\bar\varphi_s = (\varphi_{s,1},
\ldots, \varphi_{s,k})$ by using the following Bayesian procedure.
First, we use a prior distribution that says that every vector in the
simplex defined by the constraints above is equally likely.  We then
sample potential vectors $\bar\varphi$ uniformly from the
simplex. (The sampling step is implemented in the function
\texttt{sampleSimplex}, which implements the method described in
Wolfgang Huber's answer to a question on the Cross Validated part of
the web site Stack Exchange:
\url{http://stats.stackexchange.com/questions/14059/generate-uniformly-distributed-weights-that-sum-to-unity}.

Next, we compute the likelihood ($Prob(X_s | \bar\varphi_s, C_k, M_s)$)
of the observed data at each of the sampled vectors $\bar\varphi$, and
record the vector with the maximum likelihood.  Since the prior and
the sampling scheme are uniform, this is the same as the vector with
the maximum posterior probability. 

\paragraph{Code Example}
This step of the algorithm is implemented in the function
\texttt{PrefitCloneModel}.
<<pcm>>=
pcm <- PrefitCloneModel(simdata)
summary(pcm)
@ 
\begin{figure}
<<fig=TRUE,echo=FALSE>>=
hist(pcm, breaks=77)
@ 
\caption{Histogram og components of phi-vectors from first pass at
  modeling the simulated data.}
\label{hist.first}
\end{figure}

\subsubsection{Refining the Vectors $\bar\varphi$}
The precision of the estimates of $\bar\varphi_s$ arising from the
previous step depend on how many vectors we initially sampled from the
simplex.  In principle, one could improve the precision either by
sampling much more deeply or by implementing a full-blown Markov Chain
Monte Carlo (MCMC) algorithm.  In the present circumstance, however,
we can be much more efficient by borrowing strength across segments.

The idea is that the biological sample as a whole is composed of a
fairly small number of clones.  (Specifically, we do not believe that
SNP copy number data is capable of distinguishing more than about five
subclones.) We assume that there are $N$ subclones with frequencies
$\psi_i$ for $i \in 1,\ldots,N$, subject to the constraint that
$\sum_{i=1}^N \psi=1$.  Then, for each segment, the true fraction of
cells in each pure compartment must be given by a sum of a subset of
the $\psi_i$ values, and so there is a finite (and reasonably small)
number of true vectors $\bar\varphi_s$.

So, we use the posterior distribution of the ``maximum likelihood''
$\bar\varphi$ vactors as a new prior distribution.  We sample vectors
from this distribution (therefore ensuring that we sample more vectors
in a neighborhood of the most common vectors from the first pass), and
repeat the computation of likelihoods and the idenitification for each
segment of the maximum likelihood vector.  In principle, this step
could be repeated more than once; in practice, we have not yet seen
any reason to do so.  This step is implemented in the function
\texttt{updatePhiVectors}.

\paragraph{Code Example}
<<upv>>=
upv <- updatePhiVectors(pcm)
@ 
\begin{figure}
<<fig=TRUE,echo=FALSE>>=
hist(upv, breaks=55)

lp <- function(p) log(p/(1-p))
ea <- function(a) {
  temp <- exp(a)
  temp/(1+temp)
}

dang <- lp(upv@phipick)
L <- 25
dang[dang < -L] <- NA
dang[dang > L] <- NA
hist(dang, breaks=55)

@ 
\caption{Histogram of components of phi-vectors from second pass at
  modeling the simulated data.}
\label{hist.second}
\end{figure}

\subsection{Clone-Level Modeling, When The Number of Clones is Known}
Let $\Phi = [\varphi_{s,k}]$ denote the matrix of all segment-wise
compartment frequencies. In modeling terms, we can express the idea
that the data all arise from a mixture of $N$ subclones by writing
$$ \Phi = \sum_{i=1}^N \psi_i Z_i, $$
where the $\psi_i$ are as above and each $Z_i$ is an indicator matrix.
That is, each $Z_i$ is a matrix with $S$ rows (one per segment) and
$K$ columns (one per pure compartment).  Moreover, every entry in
$Z_i$ is equal either to $0$ or to $1$, and every row must contain
exactly one entry equal to $1$. In other words, each $Z-i$ specifies
which pure compartment is contained in the $i^{\rm th}$ subclone for
each segment.

\subsubsection{Initial Estimate of $\psi$}
As noted above, the true value of each $\phi_{s,k}$ should be a linear
combination of the $\psi_i$.  So, the distribution of the components
of $\bar\varphi$ shown in \fref{hist.second} should contain at least
some information about the values of $\psi_i$.  So, we shoudl start by
trying to either cluster those data or to identify the peaks in the histogram.


\subsubsection{Refined Estimate of $\psi$}

\subsection{Inferring the Number of Clones}

It would be really nice to know how to do this....

\section{Conclusions}

\end{document}



